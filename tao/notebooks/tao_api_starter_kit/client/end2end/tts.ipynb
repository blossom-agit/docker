{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### TAO remote client (TTS finetune)\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Get sample datasets (or bring your own)\n",
    "- Creating source and target datasets\n",
    "- Provide speech data\n",
    "- Creating a spectrogram generator model experiment\n",
    "- Getting a PTM from NGC\n",
    "- Actions\n",
    "  - Dataset convert\n",
    "  - Pitch stats to compute fmin, fmax, pitch_avg, pitch_std\n",
    "  - Finetune model\n",
    "  - Infer to produce data for HiFiGan\n",
    "- Process inferred data to be compatible with hifigan\n",
    "- Create a vocoder model experiment\n",
    "- Upload dataset to service\n",
    "- Get a PTM for vocoder\n",
    "- Finetune vocoder\n",
    "- Inference on sample sentences using both fast_pitch and hifigan\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Install TAO remote client](#head-1)\n",
    "1. [Set the remote service base URL](#head-2)\n",
    "1. [Access the shared volume](#head-3)\n",
    "1. [Create the datasets](#head-4)\n",
    "1. [List datasets](#head-5)\n",
    "1. [Provide specs for source dataset convert](#head-5-1)\n",
    "1. [Run source dataset convert](#head-5-2)\n",
    "1. [Create a model experiment](#head-6)\n",
    "1. [Find fastpitch pretrained model](#head-7)\n",
    "1. [Customize model metadata](#head-8)\n",
    "1. [Provide dataset convert specs to merge manifests](#head-9)\n",
    "1. [Run dataset convert to merge manifests](#head-10)\n",
    "1. [Provide pitch stats specs](#head-11)\n",
    "1. [Customize fast pitch specs](#head-12)\n",
    "1. [Run fast pitch](#head-13)\n",
    "1. [Visualize images](#head-14)\n",
    "1. [Provide finetune specs](#head-15)\n",
    "1. [Customize fast pitch specs](#head-16)\n",
    "1. [Run finetune](#head-17)\n",
    "1. [Provide infer specs](#head-18)\n",
    "1. [Customize infer specs](#head-19)\n",
    "1. [Run infer](#head-20)\n",
    "1. [Create vocoder dataset](#head-21)\n",
    "1. [Create vocoder model](#head-22)\n",
    "1. [Find hifigan pretrained model](#head-23)\n",
    "1. [Customize model metadata](#head-24)\n",
    "1. [Provide vocoder finetune specs from default](#head-25)\n",
    "1. [Customize vocoder finetune specs](#head-26)\n",
    "1. [Run vocoder finetune](#head-27)\n",
    "1. [Track logs](#head-28)\n",
    "1. [Inference from raw sentences](#head-29)\n",
    "1. [Provide model infer specs form default](#head-30)\n",
    "1. [Customize infer specs](#head-31)\n",
    "1. [Run infer](#head-32)\n",
    "1. [Track logs](#head-33)\n",
    "1. [Create dataset](#head-34)\n",
    "1. [Provide vocoder infer specs from default](#head-35)\n",
    "1. [Run vocoder infer](#head-36)\n",
    "1. [Track logs](#head-37)\n",
    "1. [Display audio](#head-38)\n",
    "1. [Delete experiment](#head-39)\n",
    "1. [Delete datasets](#head-40)\n",
    "1. [Unmount shared volume](#head-41)\n",
    "1. [Uninstall TAO Remote Client](#head-42)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import getpass\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign the ip_address and port_number in FIXME 1 and FIXME 2 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "2. Set NGC API key in FIXME 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "namespace = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Install TAO remote client <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # SKIP this step IF you have already installed the TAO-Client wheel.\n",
    "! pip3 install nvidia-tao-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the version of the TAO-Client\n",
    "! tao-client --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Set the remote service base URL <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the node_addr and port number\n",
    "node_addr = \"<ip_address>\" # FIXME1 example: 10.137.149.22\n",
    "node_port = \"<port_number>\" # FIXME2 example: 32334\n",
    "# In host machine, node ip_address and port number can be obtained as follows,\n",
    "# ip_address: hostname -i\n",
    "# port_number: kubectl get service ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "%env BASE_URL=http://{node_addr}:{node_port}/{namespace}/api/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FIXME: Set ngc_api_key valiable\n",
    "ngc_api_key = \"<ngc_api_key>\" # FIXME3 example: zZYtczM5amdtdDcwNjk0cnA2bGU2bXQ3bnQ6NmQ4NjNhMDItMTdmZS00Y2QxLWI2ZjktNmE5M2YxZTc0OGyM\n",
    "\n",
    "# Exchange NGC_API_KEY for JWT\n",
    "identity = json.loads(subprocess.getoutput(f'tao-client login --ngc-api-key {ngc_api_key}'))\n",
    "\n",
    "%env USER={identity['user_id']}\n",
    "%env TOKEN={identity['token']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Access the shared volume <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get PVC ID\n",
    "pvc_id = subprocess.getoutput(f'kubectl get pvc tao-toolkit-api-pvc -n {namespace} -o jsonpath=\"{{.spec.volumeName}}\"')\n",
    "print(pvc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get NFS server info\n",
    "provisioner = json.loads(subprocess.getoutput(f'helm get values nfs-subdir-external-provisioner -o json'))\n",
    "nfs_server = provisioner['nfs']['server']\n",
    "nfs_path = provisioner['nfs']['path']\n",
    "print(nfs_server, nfs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = getpass.getuser()\n",
    "home = os.path.expanduser('~')\n",
    "\n",
    "! echo \"Password for {user}\"\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mount shared volume \n",
    "! mkdir -p ~/shared\n",
    "\n",
    "command = \"apt-get -y install nfs-common >> /dev/null\"\n",
    "! echo {password} | sudo -S -k {command}\n",
    "\n",
    "command = f\"mount -t nfs {nfs_server}:{nfs_path}/{namespace}-tao-toolkit-api-pvc-{pvc_id} ~/shared\"\n",
    "! echo {password} | sudo -S -k {command} && echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create the datasets <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this notebook, it is assumed that you have:\n",
    "\n",
    " - Pretrained FastPitch and HiFiGAN models that were trained on `LJSpeech` sampled at 22kHz\n",
    " \n",
    "In the case that you are not using a TTS model trained on `LJSpeech` at the correct sampling rate. Please ensure that you have the original data, including wav files and a .json manifest file. If you have a TTS model but not at 22kHz, please ensure that you set the correct sampling rate, and fft parameters.\n",
    "\n",
    "For the rest of the notebook, we will be using a toy dataset consisting of 5 mins of audio. This dataset is for demo purposes only. For a good quality model, we recommend at least 30 minutes of audio. We recommend using the [NVIDIA Custom Voice Recorder](https://developer.nvidia.com/riva-voice-recorder-early-access) tool, to generate a good dataset for finetuning.\n",
    "\n",
    "Let's first download the original LJSpeech dataset. We download the toy dataset after. Then, using the API, we create these datasets and upload them to the service in the required format. Note that for the ljspeech source data, we need to run the convert action in order to create manifest files from the metadata.csv\n",
    "\n",
    "The first step downloads audio to text file lists from NVIDIA for LJSpeech and generates the manifest files. If you use your own dataset, you have to generate three files: `ljs_audio_text_train_filelist.txt`, `ljs_audio_text_val_filelist.txt`, `ljs_audio_text_test_filelist.txt` yourself and place it inside the ljspeech directory created below. Those files correspond to your train / val / test split. For each text file, the number of rows should be equal to number of samples in this split and each row should be like:\n",
    "\n",
    "```\n",
    "DUMMY/<file_name>.wav|<text_of_the_audio>\n",
    "```\n",
    "\n",
    "An example row is:\n",
    "\n",
    "```\n",
    "DUMMY/LJ045-0096.wav|Mrs. De Mohrenschildt thought that Oswald,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_dataset_id = subprocess.getoutput(\"tao-client spectro-gen dataset-create  --dataset_type speech --dataset_format ljspeech\")\n",
    "print(source_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! mkdir -p ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}/ljspeech\n",
    "! curl https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2 | tar -xvj -C ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}/ljspeech/ --strip-components 1\n",
    "! chmod 777 ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}/ljspeech\n",
    "! chmod 777 ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}/ljspeech/wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_dataset_id = subprocess.getoutput(\"tao-client spectro-gen dataset-create  --dataset_type speech --dataset_format custom\")\n",
    "print(target_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! curl https://nemo-public.s3.us-east-2.amazonaws.com/6097_5_mins.tar.gz | tar -xvz -C ~/shared/users/{os.environ['USER']}/datasets/{target_dataset_id}/ --strip-components 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auxillary_dataset_id = subprocess.getoutput(\"tao-client spectro-gen dataset-create  --dataset_type speech --dataset_format auxillary\")\n",
    "print(auxillary_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downloading auxillary files to train.\n",
    "!wget -q -P ~/shared/users/{os.environ['USER']}/datasets/{auxillary_dataset_id}/ https://github.com/NVIDIA/NeMo/raw/v1.9.0/scripts/tts_dataset_files/cmudict-0.7b_nv22.01\n",
    "!wget -q -P ~/shared/users/{os.environ['USER']}/datasets/{auxillary_dataset_id}/ https://github.com/NVIDIA/NeMo/raw/v1.9.0/scripts/tts_dataset_files/heteronyms-030921\n",
    "!wget -q -P ~/shared/users/{os.environ['USER']}/datasets/{auxillary_dataset_id}/  https://github.com/NVIDIA/NeMo/raw/v1.9.0//nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### List datasets <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = os.path.join(home, 'shared', 'users', os.environ['USER'], 'datasets', '*', 'metadata.json')\n",
    "\n",
    "datasets = []\n",
    "for metadata_path in glob.glob(pattern):\n",
    "    with open(metadata_path, 'r') as metadata_file:\n",
    "        datasets.append(json.load(metadata_file))\n",
    "\n",
    "print(json.dumps(datasets, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide source dataset convert specs <a class=\"anchor\" id=\"head-5-1\"></a>\n",
    "\n",
    "\n",
    "- First we generate manifest for the \"source\" ljspeech dataset by running the convert action on the ljspeech format dataset\n",
    "- Then we merge the ljspeech with target dataset by running the model dataset_convert action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen dataset-convert-defaults --id {source_dataset_id} --action convert | tee ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}/specs/convert.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run source dataset convert <a class=\"anchor\" id=\"head-5-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_convert_job_id = subprocess.getoutput(\"tao-client spectro-gen dataset-convert --action convert --id \" + source_dataset_id)\n",
    "print(source_convert_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_tail(logs_dir, log_file):\n",
    "    %env LOG_FILE={logs_dir}/{log_file}\n",
    "    ! mkdir -p {logs_dir}\n",
    "    ! [ ! -f \"$LOG_FILE\" ] && touch $LOG_FILE && chmod 666 $LOG_FILE\n",
    "    ! tail -f -n +1 $LOG_FILE | while read LINE; do echo \"$LINE\"; [[ \"$LINE\" == \"EOF\" ]] && pkill -P $$ tail; done\n",
    "    \n",
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'datasets', source_dataset_id, 'logs')\n",
    "log_file = f\"{source_convert_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create a model experiment <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectro_gen_model_id = subprocess.getoutput(\"tao-client spectro-gen model-create --network_arch spectro_gen --encryption_key tlt_encode\")\n",
    "print(spectro_gen_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Find fastpitch pretrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "fastpitch_ptm_id = None\n",
    "for metadata_path in glob.glob(pattern):\n",
    "  with open(metadata_path, 'r') as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "    ngc_path = metadata.get(\"ngc_path\")\n",
    "    if ngc_path and \"fastpitch:1.8.1\" in ngc_path:\n",
    "      fastpitch_ptm_id = metadata[\"id\"]\n",
    "      break\n",
    "\n",
    "print(fastpitch_ptm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Customize model metadata <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", spectro_gen_model_id, \"metadata.json\")\n",
    "\n",
    "with open(metadata_path , \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata[\"train_datasets\"] = [source_dataset_id, target_dataset_id]\n",
    "metadata[\"eval_dataset\"] = target_dataset_id\n",
    "metadata[\"inference_dataset\"] = target_dataset_id\n",
    "metadata[\"ptm\"] = fastpitch_ptm_id\n",
    "\n",
    "with open(metadata_path, \"w\") as metadata_file:\n",
    "    json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide dataset convert specs to merge manifests <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen model-dataset-convert-defaults --id {spectro_gen_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/specs/dataset_convert.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run target dataset convert to merge manifests <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_convert_job_id = subprocess.getoutput(\"tao-client spectro-gen model-dataset-convert --id \" + spectro_gen_model_id)\n",
    "print(target_convert_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', spectro_gen_model_id, 'logs')\n",
    "log_file = f\"{target_convert_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide pitch stats specs <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen dataset-pitch-stats-defaults --id {target_dataset_id} | tee ~/shared/users/{os.environ['USER']}/datasets/{target_dataset_id}/specs/pitch_stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Customize fast pitch specs <a class=\"anchor\" id=\"head-12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"datasets\", target_dataset_id, \"specs\", \"pitch_stats.json\")\n",
    "\n",
    "with open(specs_path, \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "specs[\"pitch_fmin\"] = 65\n",
    "specs[\"pitch_fmax\"] = 2094\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run fast pitch <a class=\"anchor\" id=\"head-13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pitch_stats_job_id = subprocess.getoutput(\"tao-client spectro-gen dataset-pitch-stats --id \" + target_dataset_id)\n",
    "print(pitch_stats_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'datasets', target_dataset_id, 'logs')\n",
    "log_file = f\"{pitch_stats_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Visualize images <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 install matplotlib==3.3.3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=2, num_images=10):\n",
    "    \"\"\"Visualize images in the notebook.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Path to the directory containing images.\n",
    "        num_cols (int): Number of columns.\n",
    "        num_images (int): Number of images.\n",
    "\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[240,90])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx // num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img)\n",
    "\n",
    "path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'datasets', target_dataset_id, pitch_stats_job_id)\n",
    "visualize_images(path, num_cols=5, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide finetune specs <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen model-finetune-defaults --id {spectro_gen_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/specs/finetune.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Customize fast pitch specs <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", spectro_gen_model_id, \"specs\", \"finetune.json\")\n",
    "\n",
    "with open(specs_path, \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "# Apply changes from pitch_stats job\n",
    "specs[\"n_speakers\"] = 2\n",
    "specs[\"pitch_fmin\"] = 65\n",
    "specs[\"pitch_fmax\"] = 2094\n",
    "specs[\"pitch_avg\"] = 117.27540199742586\n",
    "specs[\"pitch_std\"] = 22.1851002822779\n",
    "specs[\"trainer\"] = {\"max_epochs\":2}\n",
    "specs[\"train_ds\"][\"dataloader_params\"][\"batch_size\"] = 4\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run finetune <a class=\"anchor\" id=\"head-17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectro_gen_finetune_job_id = subprocess.getoutput(\"tao-client spectro-gen model-finetune --id \" + spectro_gen_model_id)\n",
    "print(spectro_gen_finetune_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', spectro_gen_model_id, 'logs')\n",
    "log_file = f\"{spectro_gen_finetune_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide infer specs <a class=\"anchor\" id=\"head-18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen model-infer-defaults --id {spectro_gen_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/specs/infer.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Customize infer specs <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", spectro_gen_model_id, \"specs\", \"infer.json\")\n",
    "\n",
    "with open(specs_path, \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "specs[\"mode\"] = \"infer_hifigan_ft\"\n",
    "specs[\"speaker\"] = 1\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run infer <a class=\"anchor\" id=\"head-20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectro_gen_infer_job_id = subprocess.getoutput(f\"tao-client spectro-gen model-infer --id {spectro_gen_model_id} --job {spectro_gen_finetune_job_id}\")\n",
    "print(spectro_gen_infer_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{spectro_gen_infer_job_id}.txt\"\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocoder dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel1_dataset_id = subprocess.getoutput(\"tao-client vocoder dataset-create  --dataset_type mel_spectrogram --dataset_format hifigan\")\n",
    "print(mel1_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copy data\n",
    "! mkdir -p ~/shared/users/{os.environ['USER']}/datasets/{mel1_dataset_id}/mel_spectrogram\n",
    "! cp ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/{spectro_gen_infer_job_id}/*.npy ~/shared/users/{os.environ['USER']}/datasets/{mel1_dataset_id}/mel_spectrogram/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create data manifest\n",
    "manifest_in = os.path.join(home, 'shared', 'users', os.environ['USER'], \"datasets\", target_dataset_id, \"manifest.json\")\n",
    "manifest_out = os.path.join(home, 'shared', 'users', os.environ['USER'], \"datasets\", mel1_dataset_id, \"manifest.json\")\n",
    "\n",
    "with open(manifest_in, \"r\") as infile:\n",
    "    lines = infile.readlines()\n",
    "\n",
    "with open(manifest_out,\"w+\") as outfile:\n",
    "    for cnt, line in enumerate(lines):\n",
    "        line_dict = json.loads(line)\n",
    "        line_dict[\"mel_filepath\"] = f\"mel_spectrogram/{cnt}.npy\"\n",
    "        outfile.write(json.dumps(line_dict) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocoder model <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocoder_model_id = subprocess.getoutput(\"tao-client vocoder model-create --network_arch vocoder --encryption_key tlt_encode\")\n",
    "print(vocoder_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find hifigan pretrained model <a class=\"anchor\" id=\"head-23\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "hifigan_ptm_id = None\n",
    "for metadata_path in glob.glob(pattern):\n",
    "  with open(metadata_path, 'r') as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "    ngc_path = metadata.get(\"ngc_path\")\n",
    "    if ngc_path and \"hifigan:1.0.0rc1\" in ngc_path:\n",
    "      hifigan_ptm_id = metadata[\"id\"]\n",
    "      break\n",
    "\n",
    "print(hifigan_ptm_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize model metadata <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", vocoder_model_id, \"metadata.json\")\n",
    "\n",
    "with open(metadata_path , \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata[\"train_datasets\"] = [mel1_dataset_id]\n",
    "metadata[\"eval_dataset\"] = mel1_dataset_id\n",
    "metadata[\"ptm\"] = hifigan_ptm_id\n",
    "\n",
    "with open(metadata_path, \"w\") as metadata_file:\n",
    "    json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide vocoder finetune specs from default <a class=\"anchor\" id=\"head-25\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client vocoder model-finetune-defaults --id {vocoder_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{vocoder_model_id}/specs/finetune.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize vocoder finetune specs <a class=\"anchor\" id=\"head-26\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", vocoder_model_id, \"specs\", \"finetune.json\")\n",
    "\n",
    "with open(specs_path, \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "specs[\"trainer\"] = {\"max_epochs\": 2}\n",
    "specs[\"training_ds\"][\"dataloader_params\"][\"batch_size\"] = 4\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run vocoder finetune <a class=\"anchor\" id=\"head-27\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocoder_finetune_job_id = subprocess.getoutput(f\"tao-client vocoder model-finetune --id {vocoder_model_id}\")\n",
    "print(vocoder_finetune_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track logs <a class=\"anchor\" id=\"head-28\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', vocoder_model_id, 'logs')\n",
    "log_file = f\"{vocoder_finetune_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference from raw sentences <a class=\"anchor\" id=\"head-29\"></a>\n",
    "- Take some sentences and run spectro_gen inference\n",
    "- Then use the output of this to generate vocoder inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = [\"by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\",\n",
    "             \"director rob marshall went out gunning to make a great one .\",\n",
    "             \"uneasy mishmash of styles and genres .\"   \n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide model infer specs form default <a class=\"anchor\" id=\"head-30\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client spectro-gen model-infer-defaults --id {spectro_gen_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/specs/infer.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize infer specs <a class=\"anchor\" id=\"head-31\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", spectro_gen_model_id, \"specs\", \"infer.json\")\n",
    "\n",
    "with open(specs_path, \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "specs[\"mode\"] = \"infer\"\n",
    "specs[\"input_batch\"] = sentences\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run infer <a class=\"anchor\" id=\"head-32\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectro_gen_infer_job_id = subprocess.getoutput(f\"tao-client spectro-gen model-infer --id {spectro_gen_model_id} --job {spectro_gen_finetune_job_id}\")\n",
    "print(spectro_gen_infer_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track logs <a class=\"anchor\" id=\"head-33\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', spectro_gen_model_id, 'logs')\n",
    "log_file = f\"{spectro_gen_infer_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset <a class=\"anchor\" id=\"head-34\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mel2_dataset_id = subprocess.getoutput(\"tao-client vocoder dataset-create --dataset_type mel_spectrogram --dataset_format raw\")\n",
    "print(mel2_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add inference dataset to vocoder model metadata\n",
    "metadata_path = os.path.join(home, 'shared', 'users', os.environ['USER'], \"models\", vocoder_model_id, \"metadata.json\")\n",
    "\n",
    "with open(metadata_path , \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata[\"inference_dataset\"] = mel2_dataset_id\n",
    "\n",
    "with open(metadata_path, \"w\") as metadata_file:\n",
    "    json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copy data\n",
    "! mkdir -p ~/shared/users/{os.environ['USER']}/datasets/{mel2_dataset_id}/mel_spectrogram\n",
    "! cp ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}/{spectro_gen_infer_job_id}/*.npy ~/shared/users/{os.environ['USER']}/datasets/{mel2_dataset_id}/mel_spectrogram/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide vocoder infer specs from default <a class=\"anchor\" id=\"head-35\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! tao-client vocoder model-infer-defaults --id {vocoder_model_id} | tee ~/shared/users/{os.environ['USER']}/models/{vocoder_model_id}/specs/infer.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run vocoder infer <a class=\"anchor\" id=\"head-36\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocoder_infer_job_id = subprocess.getoutput(f\"tao-client vocoder model-infer --id {vocoder_model_id} --job {vocoder_finetune_job_id}\")\n",
    "print(vocoder_infer_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track logs <a class=\"anchor\" id=\"head-37\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', vocoder_model_id, 'logs')\n",
    "log_file = f\"{vocoder_infer_job_id}.txt\"\n",
    "\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display audio <a class=\"anchor\" id=\"head-38\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(f\"{home}/shared/users/{os.environ['USER']}/models/{vocoder_model_id}/{vocoder_infer_job_id}/0.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete experiment <a class=\"anchor\" id=\"head-39\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! rm -rf ~/shared/users/{os.environ['USER']}/models/{spectro_gen_model_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/models/{vocoder_model_id}\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete datasets <a class=\"anchor\" id=\"head-40\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{source_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{target_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{auxillary_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{mel1_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{mel2_dataset_id}\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unmount shared volume <a class=\"anchor\" id=\"head-41\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "command = \"umount ~/shared\"\n",
    "! echo {password} | sudo -S -k {command} && echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninstall TAO Remote Client <a class=\"anchor\" id=\"head-42\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 uninstall -y nvidia-tao-client"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
