{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to demonstrate AutoML workflow for TAO Object Detection models\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "\n",
    "### Learning Objective\n",
    "\n",
    "This AutoML notebook applies to identifying the optimal hyperparameters (e.g., learning rate, batch size, weight regularizer, number of layers, etc.) in order to obtain better accuracy results or converge faster on AI models for object detection application.\n",
    "- Take a pretrained model and choose automl algorithm/parameters to start AutoML train.\n",
    "- At the end of an AutoML run, you will receive a config file that specifies the best performing model, along with the binary model file to deploy it to your application.\n",
    "\n",
    "\n",
    "### AutoML Workflow\n",
    "\n",
    "User starts with selecting model topology, create and upload dataset, configuring parameters, training with AutoML to comparing the model.\n",
    "\n",
    "![image](https://raw.githubusercontent.com/vpraveen-nv/model_card_images/main/api/automl_workflow.png)\n",
    "\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Create and upload datasets](#head-1)\n",
    "1. [List the created datasets](#head-2)\n",
    "1. [Dataset convert Action](#head-3)\n",
    "1. [Create model](#head-4)\n",
    "1. [List models](#head-5)\n",
    "1. [Assign train, eval datasets](#head-6)\n",
    "1. [Assign PTM](#head-7)\n",
    "1. [Set AutoML related configurations](#head-8)\n",
    "1. [Actions](#head-9)\n",
    "1. [AutoML Train](#head-10)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "2. Assign a workdir in FIXME 2\n",
    "3. Assign the ip_address and port_number in FIXME 3 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "4. Assign the ngc_api_key variable in FIXME 4\n",
    "5. Choose between default and custom dataset in FIXME 5\n",
    "6. Assign path of DATA_DIR in FIXME 6\n",
    "7. Choose between Bayesian and Hyperband automl_algorithm in FIXME 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. detectnet_v2 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/detectnet_v2.html\n",
    "# 2. efficientdet - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/efficientdet.html\n",
    "# 3. faster_rcnn - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/fasterrcnn.html\n",
    "# 4. retinanet - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/retinanet.html\n",
    "# 5. ssd - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/ssd.html\n",
    "# 6. yolo_v3 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v3.html\n",
    "# 7. yolo_v4 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4.html\n",
    "# 8. yolo_v4_tiny - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4_tiny.html\n",
    "\n",
    "model_name = \"detectnet_v2\" # FIXME1 (Add the model name from the above mentioned list)\n",
    "workdir = \"workdir_object_detection\" # FIXME2\n",
    "host_url = \"http://<ip_address>:<port_number>\" # FIXME3 example: https://10.137.149.22:32334\n",
    "# In host machine, node ip_address and port number can be obtained as follows,\n",
    "# ip_address: hostname -i\n",
    "# port_number: kubectl get service ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "ngc_api_key = \"<ngc_api_key>\" # FIXME4 example: zZYtczM5amdtdDcwNjk0cnA2bGU2bXQ3bnQ6NmQ4NjNhMDItMTdmZS00Y2QxLWI2ZjktNmE5M2YxZTc0OGyM\n",
    "dataset_to_be_used = \"default\" #FIXME5 example: default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "response = requests.get(f\"{host_url}/api/v1/login/{ngc_api_key}\")\n",
    "user_id = response.json()[\"user_id\"]\n",
    "print(\"User ID\",user_id)\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)\n",
    "\n",
    "# Set base URL\n",
    "base_url = f\"{host_url}/api/v1/user/{user_id}\"\n",
    "print(\"API Calls will be forwarded to\",base_url)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating workdir\n",
    "if not os.path.isdir(workdir):\n",
    "    os.makedirs(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use dataset in `KIITI format` for Object Detection in AutoML. Any other dataset format must be converted to kitti format. Kitti based dataset should container a folder \"images\" with all the images and a folder named \"labels\" containing the annotations in txt file format. As an example kitti based dataset, we will use FLIR20 and FLIR20_VAL dataset that has been tarballed and stored here at: [link1](https://drive.google.com/file/d/1HBIAWCwdckANkvLNvDlOiyS4ER5Y1m3L/view?usp=sharing) and [link2](https://drive.google.com/file/d/1zkO4uOUkc6CEtMKPkxJOfWMYh-R4MpN2/view?usp=sharing). \n",
    "\n",
    "**Download the two tar files and place it in $DATA_DIR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "DATA_DIR/flir20_train\n",
    "├── images/\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "\n",
    "DATA_DIR/flir20_eval\n",
    "├── images\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "```\n",
    "The file name should be same for images and labels folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = model_name # FIXME6\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if flir dataset's tar file exists and untar them\n",
    "if dataset_to_be_used == \"default\":\n",
    "    if os.path.exists(f\"{DATA_DIR}/flir20_train.tar.gz\"):\n",
    "        print(\"FLIR train tar file found\")\n",
    "        if model_name == \"efficientdet\":\n",
    "            print(\"Untarring file\")\n",
    "            !tar -xzf {DATA_DIR}/flir20_train.tar.gz -C {DATA_DIR}/\n",
    "    else:\n",
    "        print(\"FLIR train tar file not found\")\n",
    "\n",
    "    if os.path.exists(f\"{DATA_DIR}/flir20_eval.tar.gz\"):\n",
    "        print(\"FLIR val tar file found\")\n",
    "        if model_name == \"efficientdet\":\n",
    "            print(\"Untarring file\")\n",
    "            !tar -xzf {DATA_DIR}/flir20_eval.tar.gz -C {DATA_DIR}/\n",
    "    else:\n",
    "        print(\"FLIR val tar file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name == \"efficientdet\":\n",
    "    !python3 -m pip install ujson\n",
    "    !python3 -m pip install opencv-python\n",
    "    !python3 -m pip install tqdm\n",
    "    import subprocess\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"flir20_train\")):\n",
    "        print(\"Train dataset not present\")\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"flir20_eval\")):\n",
    "        print(\"Eval dataset not present\")\n",
    "    \n",
    "    #kitti to coco conversion for efficientdet\n",
    "    num_classes = subprocess.getoutput(f'python3 ../dataset_prepare/kitti/kitti_to_coco.py {DATA_DIR}/flir20_train/labels {DATA_DIR}/flir20_train')\n",
    "    subprocess.getoutput(f'python3 ../dataset_prepare/kitti/kitti_to_coco.py {DATA_DIR}/flir20_eval/labels {DATA_DIR}/flir20_eval')\n",
    "    !tar -C {DATA_DIR}/flir20_train -czf {DATA_DIR}/flir20_train.tar.gz images annotations.json\n",
    "    !tar -C {DATA_DIR}/flir20_eval -czf {DATA_DIR}/flir20_eval.tar.gz images annotations.json\n",
    "else:\n",
    "    if dataset_to_be_used == \"custom\":\n",
    "        !tar -C {DATA_DIR}/flir20_train -czf {DATA_DIR}/flir20_train.tar.gz images labels\n",
    "        !tar -C {DATA_DIR}/flir20_eval -czf {DATA_DIR}/flir20_eval.tar.gz images labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_type = \"object_detection\"\n",
    "train_dataset_path = f\"{DATA_DIR}/flir20_train.tar.gz\"\n",
    "eval_dataset_path = f\"{DATA_DIR}/flir20_eval.tar.gz\"\n",
    "\n",
    "if model_name == \"efficientdet\":\n",
    "    ds_format = \"coco\"\n",
    "else:\n",
    "    ds_format = \"kitti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update\n",
    "dataset_information = {\"name\":\"Train Dataset\",\n",
    "                       \"description\":\"My train dataset\"}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(train_dataset_path,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create eval dataset\n",
    "data = json.dumps({\"type\":ds_type,\"format\":ds_format})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "eval_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update\n",
    "dataset_information = {\"name\":\"Eval dataset\",\n",
    "                       \"description\":\"My eval dataset\"}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Upload\n",
    "files = [(\"file\",open(eval_dataset_path,\"rb\"))]\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}/upload\"\n",
    "\n",
    "response = requests.post(endpoint, files=files, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/dataset\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset convert Action <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose dataset convert action\n",
    "if model_name in (\"ssd\", \"retinanet\"):\n",
    "    convert_action = \"convert_and_index\"\n",
    "elif model_name in (\"efficientdet\"):\n",
    "    convert_action = \"convert_efficientdet\"\n",
    "else:\n",
    "    convert_action = \"convert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}/specs/{convert_action}/schema\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "\n",
    "specs = response.json()[\"default\"]\n",
    "\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "if model_name == \"efficientdet\":\n",
    "    specs[\"coco_config\"][\"num_shards\"] = 256\n",
    "    specs[\"coco_config\"][\"tag\"] = \"train\"\n",
    "else:\n",
    "    specs[\"kitti_config\"][\"image_extension\"] = \".jpg\" #Change to png if your entire dataset is of png format\n",
    "\n",
    "if convert_action == \"convert_and_index\":\n",
    "    #Change this to the classes your dataset has\n",
    "    specs[\"target_class_mapping\"] = [   {\"key\":\"bus\",\"value\":\"bus\"},\n",
    "                                        {\"key\":\"person\",\"value\":\"person\"},\n",
    "                                    ]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}/specs/{convert_action}\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [convert_action]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "ds_convert_id = response.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "job_id = ds_convert_id\n",
    "endpoint = f\"{base_url}/dataset/{dataset_id}/job/{job_id}\"\n",
    "\n",
    "while True:    \n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(response.json())\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, repeat the same for the eval dataset\n",
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}/specs/{convert_action}/schema\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "print(response)\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "if model_name == \"efficientdet\":\n",
    "    specs[\"coco_config\"][\"num_shards\"] = 256\n",
    "    specs[\"coco_config\"][\"tag\"] = \"val\"\n",
    "else:\n",
    "    specs[\"kitti_config\"][\"image_extension\"] = \".jpg\" #Change to png if your entire dataset is of png format\n",
    "\n",
    "if convert_action == \"convert_and_index\":\n",
    "    specs[\"target_class_mapping\"] = [   {\"key\":\"bus\",\"value\":\"bus\"},\n",
    "                                        {\"key\":\"person\",\"value\":\"person\"},\n",
    "                                    ]\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}/specs/{convert_action}\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [convert_action]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "eval_ds_convert_id = response.json()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "job_id = eval_ds_convert_id\n",
    "endpoint = f\"{base_url}/dataset/{eval_dataset_id}/job/{job_id}\"\n",
    "\n",
    "while True:    \n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(response.json())\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_arch = model_name\n",
    "encode_key = \"tlt_encode\"\n",
    "data = json.dumps({\"network_arch\":network_arch,\"encryption_key\":encode_key})\n",
    "\n",
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "model_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List models <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "print(response)\n",
    "# print(response.json()) ## Uncomment for verbose list output\n",
    "\n",
    "print(\"model id\\t\\t\\t     network architecture\")\n",
    "for rsp in response.json():\n",
    "    print(rsp[\"id\"],rsp[\"network_arch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets <a class=\"anchor\" id=\"head-6\"></a>\n",
    "\n",
    "- Note: make sure the order for train_datasets is [source ID, target ID]\n",
    "- eval_dataset is kept same as target for demo purposes\n",
    "- inference_dataset is kept as target for chaining with hifigan finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_information = {\"train_datasets\":[dataset_id],\n",
    "                       \"eval_dataset\":eval_dataset_id}\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-7\"></a>\n",
    "\n",
    "Search for pretrained models on NGC and assign it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different object detection models\n",
    "# print base_url+\"/model\" to get the details of all pretrained models and make the appropriate changes to this map for experiments like for example \n",
    "# you are changing the number of layers to 34, then you have to make the appropriate change in the pretrained model name\n",
    "# print(base_url+\"/model\")\n",
    "pretrained_map = {\"detectnet_v2\" : \"detectnet_v2:resnet18\",\n",
    "                  \"efficientdet\" : \"pretrained_efficientdet:efficientnet_b0\",\n",
    "                  \"faster_rcnn\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"retinanet\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"ssd\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v3\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4_tiny\": \"pretrained_object_detection:cspdarknet_tiny\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get pretrained model\n",
    "model_list = f\"{base_url}/model\"\n",
    "response = requests.get(model_list, headers=headers)\n",
    "\n",
    "response_json = response.json()\n",
    "\n",
    "# Search for ptm with given ngc path\n",
    "ptm_id = None\n",
    "for rsp in response_json:\n",
    "    if  rsp[\"network_arch\"] == network_arch and pretrained_map[network_arch] in rsp[\"ngc_path\"]:\n",
    "        ptm_id = rsp[\"id\"]\n",
    "        print(\"Metadata for model with requested NGC Path\")\n",
    "        print(rsp)\n",
    "        break\n",
    "ptm = ptm_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptm_information = {\"ptm\":ptm}\n",
    "data = json.dumps(ptm_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View hyperparameters that are enabled for AutoML by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{model_id}/specs/train/schema\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "specs = response.json()[\"automl_default_parameters\"]\n",
    "\n",
    "import json\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set AutoML related configurations <a class=\"anchor\" id=\"head-8\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters: [DetectNet_V2](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id4), \n",
    "[EfficientDet](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id13), \n",
    "[FasterRCNN](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id16), \n",
    "[RetinaNet](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id32), \n",
    "[SSD](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id38), \n",
    "[YOLO_V3](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id52), \n",
    "[YOLO_V4](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id58), \n",
    "[YOLO_V4_Tiny](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_action_specs.html#id58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose automl algorithm between \"Bayesian\" and \"HyperBand\".\n",
    "automl_algorithm=\"Bayesian\" # FIXME7 example: Bayesian/HyperBand\n",
    "\n",
    "#Don't change this, in future multiple metrics will be supported\n",
    "if model_name == \"efficientdet\":\n",
    "    metric = \"kpi\"\n",
    "else:\n",
    "    metric = \"map\"\n",
    "\n",
    "additional_automl_parameters = [] #Refer to parameter list mentioned in the above links and add any extra parameter in addition to the default enabled ones\n",
    "remove_default_automl_parameters = [] #Remove any hyperparameters that are enabled by default for AutoML\n",
    "\n",
    "automl_information = {\"automl_enabled\":True,\n",
    "                      \"automl_algorithm\":automl_algorithm,\n",
    "                      \"metric\":metric,\n",
    "                      \"automl_add_hyperparameters\":str(additional_automl_parameters),\n",
    "                      \"automl_remove_hyperparameters\":str(remove_default_automl_parameters)\n",
    "                     }\n",
    "data = json.dumps(automl_information)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "import json\n",
    "print(json.dumps(response.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions <a class=\"anchor\" id=\"head-9\"></a>\n",
    "\n",
    "For all actions:\n",
    "1. Get default spec schema and derive the default values\n",
    "2. Modify defaults if needed\n",
    "3. Post spec dictionary to the service\n",
    "4. Run model action\n",
    "5. Monitor job using retrieve\n",
    "6. Download results using job download endpoint (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Train <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/model/{model_id}/specs/train/schema\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "print(response)\n",
    "\n",
    "#print(response.json()) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "\n",
    "import json\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "# Example for detectnet_v2 (for each network the parameter key might be different)\n",
    "specs[\"training_config\"][\"num_epochs\"] = 80 # num_epochs is the parameter name for all object detection networks\n",
    "\n",
    "# for efficientdet\n",
    "# specs[\"training_config\"][\"train_batch_size\"] = 8\n",
    "# specs[\"training_config\"][\"num_examples_per_epoch\"] = 1257 #number of images in your dataset/number of gpu's\n",
    "# specs[\"dataset_config\"][\"num_classes\"] = int(num_classes) #num_classes was computed during kitti_to_coco_conversion\n",
    "# specs[\"eval_config\"][\"eval_epoch_cycle\"] = 10\n",
    "\n",
    "if \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "    specs[\"dataset_config\"][\"image_extension\"] = \"jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Post spec\n",
    "data = json.dumps(specs)\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}/specs/train\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "import json\n",
    "print(json.dumps(response.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "actions = [\"train\"]\n",
    "data = json.dumps({\"job\":parent,\"actions\":actions})\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}/job\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(response.json())\n",
    "\n",
    "job_map[\"train\"] = response.json()[0]\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor automl job status by repeatedly running this cell\n",
    "# Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
    "\n",
    "job_id = job_map['train']\n",
    "endpoint = f\"{base_url}/model/{model_id}/job/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To Stop an AutoML JOB\n",
    "#    1. Stop the 'Monitor automl job status by repeatedly running this cell' cell (the cell right before this cell) manually\n",
    "#    2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# job_id = job_map['train']\n",
    "# endpoint = f\"{base_url}/model/{model_id}/job/{job_id}/cancel\"\n",
    "\n",
    "# response = requests.post(endpoint, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Resume AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor automl job status by repeatedly running this cell' cell above (4th cell above from this cell)\n",
    "# job_id = job_map['train']\n",
    "# endpoint = f\"{base_url}/model/{model_id}/job/{job_id}/resume\"\n",
    "\n",
    "# response = requests.post(endpoint, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download automl job contents once the above job shows \"Done\" status\n",
    "# Download output of automl (detectnet_v2) train (Note: will take time)\n",
    "job_id = job_map[\"train\"]\n",
    "endpoint = f'{base_url}/model/{model_id}/job/{job_id}/download'\n",
    "\n",
    "# Save\n",
    "temptar = f'{job_id}.tar.gz'\n",
    "with requests.get(endpoint, headers=headers, stream=True) as r:\n",
    "    r.raise_for_status()\n",
    "    with open(temptar, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "print(\"Untarring\")\n",
    "\n",
    "# Untar to destination\n",
    "tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "os.system(tar_command)\n",
    "os.remove(temptar)\n",
    "print(f\"Results at {workdir}/{job_id}\")\n",
    "model_downloaded_path = f\"{workdir}/{job_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View best performing model's config, model file; Also view the results of all automl experiments\n",
    "!python3 -m pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "best_model_path = f\"{model_downloaded_path}/best_model\"\n",
    "\n",
    "if os.path.exists(best_model_path):        \n",
    "    #List the binary model file\n",
    "    print(\"\\nCheckpoints for the best performing experiment\")\n",
    "    if os.path.exists(best_model_path+\"/weights\") and len(os.listdir(best_model_path+\"/weights\")) > 0:\n",
    "        print(f\"Folder: {best_model_path}/weights\")\n",
    "        print(\"Files:\", os.listdir(best_model_path+\"/weights\"))\n",
    "    else:\n",
    "        print(f\"Folder: {best_model_path}\")\n",
    "        print(\"Files:\", os.listdir(best_model_path))\n",
    "\n",
    "    experiment_artifacts = json.load(open(f\"{best_model_path}/controller.json\",\"r\"))\n",
    "    data_frame = pd.DataFrame(experiment_artifacts)\n",
    "    # Print experiment id/number and the corresponding result\n",
    "    print(\"\\nResults of all experiments\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "        print(data_frame[[\"id\",\"result\"]])\n",
    "\n",
    "    print(\"\\nConfig/Spec file for the best performing experiment (recommendation_id.kitti with the maximum result value in the dataframe)\")\n",
    "    # List the recommendation config file of the best performing checkpoint(recommendation_id.kitti with the maximum result value in the dataframe)\n",
    "    !ls {best_model_path}/*.kitti "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
